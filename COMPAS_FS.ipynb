{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3316e72b-7fe1-4fde-a0b7-15bb8c332db8",
   "metadata": {},
   "source": [
    "# Yet Another ProPublica COMPAS notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d9b45-1a4e-4ce7-950c-64a9fe8f4271",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dependencias, leer datos y preprocesar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e5077-6e29-486f-846f-c2c4329b2b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "!pip install -U fairlearn \n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/javism/seminariofate2025/main/data/propublica_recidivism_train.csv')\n",
    "df_test = pd.read_csv('https://raw.githubusercontent.com/javism/seminariofate2025/main/data/propublica_recidivism_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98239639-8361-4b50-b9cb-887130c22a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mejora estética de los gráficos\n",
    "import seaborn\n",
    "import matplotlib as mpl\n",
    "#tema matplotlib por defecto\n",
    "#sty = 'default'\n",
    "sty = 'seaborn-v0_8'\n",
    "mpl.style.use(sty)\n",
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "seaborn.set_context(\"talk\")  # or \"paper\" or \"poster\"; default: \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6454c76-2955-47e8-a6ee-c16d004338b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d85958-0a89-4ab2-ad61-a2aebb56bc00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Dibujamos el histograma de las puntuaciones por \"raza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68529d77-8a7a-4018-b84e-9b733fe03e0c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['race_label'] = 'black'\n",
    "df.loc[df['race'] == 0, 'race_label'] = 'white'\n",
    "df_test['race_label'] = 'black'\n",
    "df_test.loc[df_test['race'] == 0, 'race_label'] = 'white'\n",
    "\n",
    "df['decile_score'].hist(by=df['race_label'], figsize = (8,3))\n",
    "plt.tight_layout()\n",
    "df['y'].hist(by=df['race_label'], figsize = (8,3))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f6e7bb-a39a-4999-90d2-ad13d84f747b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Comparación de variables por grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b58f15-40b2-40ca-86c0-697b80fda053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z_score_standardization(series):\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "df_s = df.copy()\n",
    "for col in df_s.columns:\n",
    "    if col != 'race_label':\n",
    "        df_s[col] = z_score_standardization(df_s[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c34f0-b0cc-47dc-badf-0ddd2676a6c6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analizamos con variables estandarizadas   \n",
    "df_s.groupby('race_label').boxplot(rot=70)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df9eee-3c5c-47c6-9680-a44eb568a4b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocesado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008b50f-fcd5-47e2-a9c8-5c05b205247d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove some variables, standarize and binarize label\n",
    "race_label = df['race_label']\n",
    "race_label_t = df_test['race_label']\n",
    "df.drop(['c_charge_desc','decile_score','score_text', 'race_label'], axis=1, inplace=True)\n",
    "df_test.drop(['c_charge_desc','decile_score','score_text', 'race_label'], axis=1, inplace=True)\n",
    "\n",
    "X = df.drop(['y'], axis=1)\n",
    "feature_names = X.columns\n",
    "y = df['y']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_test = df_test.drop(['y'], axis=1)\n",
    "y_test = df_test['y']\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f798f0fc-b126-4be9-b852-50b0c608e4f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funciones auxiliares de métricas de disparidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e86a6-44ec-45ab-b8ae-fcb560bb32d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from fairlearn.metrics import false_positive_rate\n",
    "from fairlearn.metrics import false_negative_rate\n",
    "from fairlearn.metrics import true_positive_rate\n",
    "from fairlearn.metrics import selection_rate\n",
    "from fairlearn.metrics import count\n",
    "\n",
    "def performance_metrics(y_test, predictions, race_label_t): \n",
    "    # Test for discrimination in predictions\n",
    "    from fairlearn.metrics import MetricFrame,false_negative_rate,false_positive_rate\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    grouped_metric = MetricFrame(metrics=accuracy_score,y_true=y_test,y_pred=predictions, sensitive_features=race_label_t)\n",
    "    print(f\"Overall Accuracy = \\t{grouped_metric.overall:.4f}\")\n",
    "    print(\"Accuracy by groups:\")\n",
    "    for key, value in grouped_metric.by_group.to_dict().items():\n",
    "        print(f\"Acc {key}: \\t\\t{value:.4f}\")\n",
    "\n",
    "    grouped_metric = MetricFrame(metrics=false_negative_rate,y_true=y_test,y_pred=predictions, sensitive_features=race_label_t)\n",
    "    print(f\"Overall FNR = \\t\\t{grouped_metric.overall:.4f}\")\n",
    "    print(\"FNR by groups: \")\n",
    "    for key, value in grouped_metric.by_group.to_dict().items():\n",
    "        print(f\"FNR {key}: \\t\\t{value:.4f}\")\n",
    "\n",
    "    grouped_metric = MetricFrame(metrics=false_positive_rate,y_true=y_test,y_pred=predictions, sensitive_features=race_label_t)\n",
    "    print(f\"Overall FPR = \\t\\t{grouped_metric.overall:.4f}\")\n",
    "    print(\"FPR by groups: \")\n",
    "    for key, value in grouped_metric.by_group.to_dict().items():\n",
    "        print(f\"\\x1B[1mFPR {key}: \\t\\t{value:.4f}\")\n",
    "        \n",
    "\n",
    "def performance_plots(y_test, predictions, race_label_t): \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score,\n",
    "        'precision': precision_score,\n",
    "        'recall': recall_score,\n",
    "        'false positive rate': false_positive_rate,\n",
    "        'false negative rate': false_negative_rate,\n",
    "        'count': count}\n",
    "    metric_frame = MetricFrame(metrics=metrics,\n",
    "                               y_true=y_test,\n",
    "                               y_pred=predictions,\n",
    "                               sensitive_features=race_label_t)\n",
    "    metric_frame.by_group.plot.bar(\n",
    "        subplots=True,\n",
    "        layout=[3, 3],\n",
    "        legend=False,\n",
    "        figsize=[12, 8],\n",
    "        title=\"LR\",\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8f9c5-dd1c-40ee-9af3-25272e214e53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ajustar modelo básico y evaluar\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Pregunta:</b> ¿Qué conclusiones sacas del análisis del rendimiento por grupos?.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3c7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit a logistic regression predictor\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr.score(X_test, y_test)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "performance_metrics(y_test, predictions, race_label_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7539d-fa1a-4865-a988-df05284f0971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_plots(y_test, predictions, race_label_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc0605-f2b9-4e77-b83a-e6923f3e11aa",
   "metadata": {},
   "source": [
    "## Imprimimos nuestro modelo matemático\n",
    "\n",
    "<img src=\"pics/compas_diagram_pre.png\" alt=\"COMPAS model as a graph\" class=\"bg-primary\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca677589-418a-417f-b199-c5a74157a626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intercept = lr.intercept_[0];\n",
    "print(f'{intercept:.3f} ', end=\"\")\n",
    "for c, f in zip(lr.coef_.ravel(), list(feature_names) ):\n",
    "    print(f'{c:.3f} * {f}', end=' + ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2164d-a146-45b8-b0f8-80affd8fdeb5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Pregunta:</b> ¿Qué conclusiones sacas del modelo?.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba19579",
   "metadata": {},
   "source": [
    "# Selección de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac20ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "print(X.shape)\n",
    "\n",
    "lsvc = LinearSVC(C=0.001, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X = model.transform(X)\n",
    "X_test = model.transform(X_test)\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(f\"Features selected by SelectFromModel: {feature_names[model.get_support()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31b476-8e6d-485a-bee8-476f75a82b71",
   "metadata": {},
   "source": [
    "## Reentrenamos el modelo con el filtrado de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd30763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit a logistic regression predictor\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr.score(X_test, y_test)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "performance_metrics(y_test, predictions, race_label_t)\n",
    "performance_plots(y_test, predictions, race_label_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91e581-aa75-46a4-96ed-cab058d9bce2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imprimimos nuestro modelo matemático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea357228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intercept = lr.intercept_[0];\n",
    "print(f'{intercept:.3f} ', end=\"\")\n",
    "for c, f in zip(lr.coef_.ravel(), list(feature_names[model.get_support()]) ):\n",
    "    print(f'{c:.3f} * {f}', end=' + ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fdb64d-9f52-4f89-b691-276379c2d795",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Pregunta:</b> ¿Qué conclusiones sacas del modelo podado?.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d199450-d7a8-4494-84b6-b5084c326b9d",
   "metadata": {},
   "source": [
    "## Modelo final\n",
    "\n",
    "Esta fórmula matemática equivale al modelo de la empresa NorthPointe que a partir de 137 variables dice predecir si una persona reincidirá. \n",
    "\n",
    "<img src=\"pics/compas_diagram.png\" alt=\"COMPAS model as a graph\" class=\"bg-primary\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a1ebd-5289-4fa9-b3a9-057708e0de66",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "* Cualquier modelo construído sobre los datos históricos va a reproducir desigualdades estructurales.\n",
    "\n",
    "* Incluso reduciendo las variables al mínimo estas están mediadas (término de inferencia causal) por la \"raza\".\n",
    "\n",
    "* ¿Comprarías una herramienta inteligente que predice comportamiento a partir de 137 variables?¿Y si tiene 2 variables?\n",
    "\n",
    "* Hay otras cuestiones más importantes de fondo sobre qué entendemos por justicia y la imposibilidad de implementarla algorítmicamente si consideramos que cualquier herramienta de IA no incorpora el contexto a sus decisiones.\n",
    "\n",
    "# Referencias\n",
    "* Angwin, J., & Larson, J. (2016, diciembre 30). Bias in Criminal Risk Scores Is Mathematically Inevitable, Researchers Say. ProPublica. <https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say>\n",
    "* Larson, J., & Angwin, J. (2016, mayo 23). How We Analyzed the COMPAS Recidivism Algorithm. ProPublica. <https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm>\n",
    "* Rudin, C. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nat Mach Intell 1, 206–215 (2019). <https://doi.org/10.1038/s42256-019-0048-x>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ad538-669f-441b-b7af-b71a4a24fd11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
